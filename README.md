# README

This repository is a part of the master thesis Assessing privacy vs. efficiency tradeoffs in open-source Large-Language Models, during 2025. It supports fine-tuning of Causal Language Models (LLMs) on the the Enron email dataset. It supports training on single GPU and multi-GPU setups.

## Setup environment:
  - conda create -n finetune-env python=3.10
  - conda activate finetune-env
  - pip install -r requirements.txt

## Run multiple GPUs 
 
